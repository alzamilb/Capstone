\documentclass[letterpaper,10pt]{article}

\usepackage[pdftex]{graphicx}
\usepackage{amssymb}                                         
\usepackage{amsmath}                                         
\usepackage{amsthm}                                          

\usepackage{alltt}                                           
\usepackage{float}
\usepackage{color}
\usepackage{url}
%\usepackage{tabu}
%\usepackage[utf8]{inputenc}
%\usepackage{wrapfig}
%\usepackage{multirow}
%\usepackage{amssymb}


\usepackage{balance}
\usepackage[TABBOTCAP, tight]{subfigure}
\usepackage{enumitem}
\usepackage{pstricks, pst-node}

\usepackage{geometry}
\geometry{textheight=8.5in, textwidth=6in}
\usepackage{booktabs}

%random comment

\newcommand{\cred}[1]{{\color{red}#1}}
\newcommand{\cblue}[1]{{\color{blue}#1}}

\newcommand{\toc}{\tableofcontents}

\usepackage{hyperref}
\usepackage{geometry}
\usepackage{parskip}

%\def\name{}

%pull in the necessary preamble matter for pygments output
%\input{pygments.tex}


\parindent = 0.0 in
\parskip = 0.1 in


\begin{document}

\begin{titlepage}
\begin{center}
    \textsc{\LARGE CS 461 - Fall 2016 - Requirements Document}

    \textsc{Group 32}
    
    \textsc{Team name: Teaching AutoPilot to Dodge}
    
    \emph{Member:}
    Basil Al Zamil,
    Xilun Guo, and
    Tanner Fry
    \setlength{\parskip}{20pt}

\textsc{\large ABSTRACT}
\end{center}

The primary goal of the project is to collect a dataset of real-world driving scenarios (images, video, and sensor data) where potentially problematic objects are in a frame along with bad weather and lighting scenarios. For example wildlife such as deer, cows, and birds need to be correctly identified, along with landmarks of odd shapes such as sculptures in all sorts of lighting and weather conditions. Then we will test whether current self-driving car software can detect, recognize, and accurately maneuver around unexpected and or unordinary objects. Specifically, we look at autonomous driving algorithms capability to comprehend objects given particular world conditions (such as lighting, rain, water, snow, etc). 
\end{titlepage}

\tableofcontents

\newpage

\section{Introduction}
    \subsection{Main requirements}

    Our main requirements are limited by the bugs we find. The hard goal we have is to test the algorithms used by CityScape in autonomous vehicles. Assuming there are issues with the image recognitio    n algorithms under certain conditions, we must then collect the errors we find into a single dataset that the system fails with. This can be set as a baseline of failure and be forwarded to the Ci    tyScape team. This will also open us up to the possibility of modifying the algorithms used ourselves to try and fix the errors that we found. 

    We are required to use some strategies to collect as much data as possible in the amount of time for proving if there is a situation which could break the algorithm. For example, trying to find so    me volunteers from different areas that allow us to place cameras onto their vehicles, and we can record the image dataset we collect. As a result, we will apply the algorithms from CityScape to a    nalyze the data we collect. Specifically, the Big Data we are looking for is wide angle front image of a vehicle while driving within a bad digital visual field. In addition, some objects are too     high or too low, which the camera can catch but because of the angle or camera field of view the algorithms do not analyze the image correctly. They also could not respond quickly enough to react     to driving conditions, which may lead to a car crash or to a dangerous situations.

    \subsection{Hard requirements}

    Create video and image datasets and apply them to the CityScape algorithms for testing. Then verify that all the datasets that we applied to the algorithm, where we can safely assume the algorithm    is relatively problem free towards unusual objects.

    \subsection{Soft requirements}

    Create video and image datasets that find or expose faults in the image recognition software. Then work on and try to improve the image recognition algorithm being used to try and correct the the     recognition of the unusual object(s) or lighting errors we find.

    %\subsection{Definitions}
    %\begin{tabu} to \hsize {|X|X[3,l]|}
    %\hline
    %Term & Definition \\
    %\hline
    %Volunteers & The people who interact with our project, and the target clients \\
    %\hline
    %Big Data & A large and complex data set, which is hard to deal with by traditional data processing applications, but extremely useful for the conditions analysis \\
    %\hline
    %Image recognition algorithm & Using high resoultion video record any objects on the road, and using specific technique to analyze different conditions then make the reaction \\
    %\hline
    %\end{tabu}




\section{Overall Description}
    \subsection{Planned Testing Methods}

    Since different weather conditions are a prime part of our testing objectives, a dataset from different weather conditions must be collected. Now we also need to consider different environments ar    ound the world, not just limited to our climate here in Oregon. We will do this by obtaining datasets from different environments, either from notable sources on the internet, or through contactin    g other individuals around the world. To control as many of the variables as possible, we are required to clearly understand which kinds of weather could deviate the normal algorithm function. Hea    vy rain, snow, sunny day, darkness, and direct sunlight and vehicle headlights into the camera all must be tested. Also we will focus primarily on country or side roads rather than inside city lim    its as most datasets have been primarily tested in busier settings. We will attach a decent quality camera to the inside of the car dashboard to collect video while driving. If possible we would a    lso collect GPS data.

    \subsection{Timeframe:}
    \begin{figure}[H] 
        \centering
        \includegraphics[width=15cm,height=4cm]{Gantt.JPG}
    \end{figure}

\end{document}
